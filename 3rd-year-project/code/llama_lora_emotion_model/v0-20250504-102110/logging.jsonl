{"loss": 9.23694706, "token_acc": 0.4375, "grad_norm": 80.46146393, "learning_rate": 9.99e-05, "memory(GiB)": 3.0, "train_speed(iter/s)": 0.457796, "epoch": 0.02, "global_step/max_steps": "1/50", "percentage": "2.00%", "elapsed_time": "1s", "remaining_time": "1m 35s"}
{"loss": 2.8544426, "token_acc": 0.5703125, "grad_norm": 9.47921753, "learning_rate": 9.755e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.76265, "epoch": 0.1, "global_step/max_steps": "5/50", "percentage": "10.00%", "elapsed_time": "6s", "remaining_time": "56s"}
{"loss": 0.38542938, "token_acc": 0.7875, "grad_norm": 6.18460941, "learning_rate": 9.045e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.844389, "epoch": 0.2, "global_step/max_steps": "10/50", "percentage": "20.00%", "elapsed_time": "11s", "remaining_time": "46s"}
{"loss": 0.28759775, "token_acc": 0.8625, "grad_norm": 11.93412209, "learning_rate": 7.939e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.877055, "epoch": 0.3, "global_step/max_steps": "15/50", "percentage": "30.00%", "elapsed_time": "16s", "remaining_time": "39s"}
{"loss": 0.17326541, "token_acc": 0.95625, "grad_norm": 8.21657467, "learning_rate": 6.545e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.89163, "epoch": 0.4, "global_step/max_steps": "20/50", "percentage": "40.00%", "elapsed_time": "22s", "remaining_time": "33s"}
{"loss": 0.06562775, "token_acc": 0.9875, "grad_norm": 4.8150177, "learning_rate": 5e-05, "memory(GiB)": 3.18, "train_speed(iter/s)": 0.895605, "epoch": 0.5, "global_step/max_steps": "25/50", "percentage": "50.00%", "elapsed_time": "27s", "remaining_time": "27s"}
{"loss": 0.04016051, "token_acc": 0.9875, "grad_norm": 14.3460741, "learning_rate": 3.455e-05, "memory(GiB)": 3.18, "train_speed(iter/s)": 0.896863, "epoch": 0.6, "global_step/max_steps": "30/50", "percentage": "60.00%", "elapsed_time": "33s", "remaining_time": "22s"}
{"loss": 0.02236991, "token_acc": 0.9875, "grad_norm": 1.38360727, "learning_rate": 2.061e-05, "memory(GiB)": 3.52, "train_speed(iter/s)": 0.89939, "epoch": 0.7, "global_step/max_steps": "35/50", "percentage": "70.00%", "elapsed_time": "38s", "remaining_time": "16s"}
{"loss": 0.01410553, "token_acc": 0.99375, "grad_norm": 0.46103969, "learning_rate": 9.55e-06, "memory(GiB)": 3.52, "train_speed(iter/s)": 0.904112, "epoch": 0.8, "global_step/max_steps": "40/50", "percentage": "80.00%", "elapsed_time": "44s", "remaining_time": "11s"}
{"loss": 0.01046471, "token_acc": 0.99375, "grad_norm": 0.17418225, "learning_rate": 2.45e-06, "memory(GiB)": 3.72, "train_speed(iter/s)": 0.904658, "epoch": 0.9, "global_step/max_steps": "45/50", "percentage": "90.00%", "elapsed_time": "49s", "remaining_time": "5s"}
{"loss": 0.00101348, "token_acc": 1.0, "grad_norm": 0.28922346, "learning_rate": 0.0, "memory(GiB)": 3.72, "train_speed(iter/s)": 0.90775, "epoch": 1.0, "global_step/max_steps": "50/50", "percentage": "100.00%", "elapsed_time": "54s", "remaining_time": "0s"}
{"eval_loss": 0.00947222, "eval_token_acc": 0.995, "eval_runtime": 3.1272, "eval_samples_per_second": 63.954, "eval_steps_per_second": 31.977, "epoch": 1.0, "global_step/max_steps": "50/50", "percentage": "100.00%", "elapsed_time": "57s", "remaining_time": "0s"}
{"train_runtime": 58.3164, "train_samples_per_second": 13.718, "train_steps_per_second": 0.857, "total_flos": 537326827929600.0, "train_loss": 0.51309779, "epoch": 1.0, "global_step/max_steps": "50/50", "percentage": "100.00%", "elapsed_time": "58s", "remaining_time": "0s"}
{"train_dataset": "107.065000±13.890402, min=79.000000, max=203.000000, size=800", "val_dataset": "108.835000±15.911875, min=83.000000, max=206.000000, size=200", "model_parameter_info": "PeftModelForCausalLM: 1238.6324M Params (2.8180M Trainable [0.2275%]), 0.0000M Buffers.", "last_model_checkpoint": "/root/autodl-tmp/code/llama_lora_emotion_model/v0-20250504-102110/checkpoint-50", "best_model_checkpoint": "/root/autodl-tmp/code/llama_lora_emotion_model/v0-20250504-102110/checkpoint-50", "best_metric": 0.00947222, "global_step": 50, "log_history": [{"loss": 9.236947059631348, "token_acc": 0.4375, "grad_norm": 80.46146392822266, "learning_rate": 9.990133642141359e-05, "memory(GiB)": 3.0, "train_speed(iter/s)": 0.457796, "epoch": 0.02, "step": 1}, {"loss": 2.854442596435547, "token_acc": 0.5703125, "grad_norm": 9.479217529296875, "learning_rate": 9.755282581475769e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.76265, "epoch": 0.1, "step": 5}, {"loss": 0.38542938232421875, "token_acc": 0.7875, "grad_norm": 6.184609413146973, "learning_rate": 9.045084971874738e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.844389, "epoch": 0.2, "step": 10}, {"loss": 0.2875977516174316, "token_acc": 0.8625, "grad_norm": 11.934122085571289, "learning_rate": 7.938926261462366e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.877055, "epoch": 0.3, "step": 15}, {"loss": 0.1732654094696045, "token_acc": 0.95625, "grad_norm": 8.216574668884277, "learning_rate": 6.545084971874738e-05, "memory(GiB)": 3.17, "train_speed(iter/s)": 0.89163, "epoch": 0.4, "step": 20}, {"loss": 0.06562775373458862, "token_acc": 0.9875, "grad_norm": 4.8150177001953125, "learning_rate": 5e-05, "memory(GiB)": 3.18, "train_speed(iter/s)": 0.895605, "epoch": 0.5, "step": 25}, {"loss": 0.0401605099439621, "token_acc": 0.9875, "grad_norm": 14.346074104309082, "learning_rate": 3.4549150281252636e-05, "memory(GiB)": 3.18, "train_speed(iter/s)": 0.896863, "epoch": 0.6, "step": 30}, {"loss": 0.02236991226673126, "token_acc": 0.9875, "grad_norm": 1.383607268333435, "learning_rate": 2.061073738537635e-05, "memory(GiB)": 3.52, "train_speed(iter/s)": 0.89939, "epoch": 0.7, "step": 35}, {"loss": 0.014105525612831116, "token_acc": 0.99375, "grad_norm": 0.4610396921634674, "learning_rate": 9.549150281252633e-06, "memory(GiB)": 3.52, "train_speed(iter/s)": 0.904112, "epoch": 0.8, "step": 40}, {"loss": 0.010464712232351302, "token_acc": 0.99375, "grad_norm": 0.1741822510957718, "learning_rate": 2.4471741852423237e-06, "memory(GiB)": 3.72, "train_speed(iter/s)": 0.904658, "epoch": 0.9, "step": 45}, {"loss": 0.0010134832933545112, "token_acc": 1.0, "grad_norm": 0.28922346234321594, "learning_rate": 0.0, "memory(GiB)": 3.72, "train_speed(iter/s)": 0.90775, "epoch": 1.0, "step": 50}, {"eval_loss": 0.009472223930060863, "eval_token_acc": 0.995, "eval_runtime": 3.1272, "eval_samples_per_second": 63.954, "eval_steps_per_second": 31.977, "epoch": 1.0, "step": 50}, {"train_runtime": 58.3164, "train_samples_per_second": 13.718, "train_steps_per_second": 0.857, "total_flos": 537326827929600.0, "train_loss": 0.5130977929569781, "epoch": 1.0, "step": 50}], "memory": 3.720703125}
