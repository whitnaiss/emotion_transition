{
  "best_global_step": 50,
  "best_metric": 0.00454284,
  "best_model_checkpoint": "/root/autodl-tmp/code/llama_raw_lora_model/v8-20250504-164211/checkpoint-50",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 79.8863754272461,
      "learning_rate": 0.00039960534568565434,
      "loss": 8.951247215270996,
      "memory(GiB)": 2.86,
      "step": 1,
      "token_acc": 0.4375,
      "train_speed(iter/s)": 0.461219
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4248096942901611,
      "learning_rate": 0.00039021130325903074,
      "loss": 1.2398605346679688,
      "memory(GiB)": 3.02,
      "step": 5,
      "token_acc": 0.703125,
      "train_speed(iter/s)": 0.733566
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.051389694213867,
      "learning_rate": 0.0003618033988749895,
      "loss": 0.23977794647216796,
      "memory(GiB)": 3.02,
      "step": 10,
      "token_acc": 0.88125,
      "train_speed(iter/s)": 0.823353
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.357248306274414,
      "learning_rate": 0.00031755705045849464,
      "loss": 0.016596026718616486,
      "memory(GiB)": 3.02,
      "step": 15,
      "token_acc": 0.99375,
      "train_speed(iter/s)": 0.883085
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.007300226949155331,
      "learning_rate": 0.00026180339887498953,
      "loss": 0.0005783532746136188,
      "memory(GiB)": 3.02,
      "step": 20,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.915197
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.006097486242651939,
      "learning_rate": 0.0002,
      "loss": 0.061790931224823,
      "memory(GiB)": 3.02,
      "step": 25,
      "token_acc": 0.99375,
      "train_speed(iter/s)": 0.936151
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.03865686058998108,
      "learning_rate": 0.00013819660112501054,
      "loss": 0.003246067464351654,
      "memory(GiB)": 3.03,
      "step": 30,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.939671
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.0025290902704000473,
      "learning_rate": 8.24429495415054e-05,
      "loss": 4.141776589676738e-05,
      "memory(GiB)": 3.36,
      "step": 35,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.938219
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0012596516171470284,
      "learning_rate": 3.819660112501053e-05,
      "loss": 0.0010278048925101758,
      "memory(GiB)": 3.36,
      "step": 40,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.945282
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.0011038788361474872,
      "learning_rate": 9.788696740969295e-06,
      "loss": 0.12034173011779785,
      "memory(GiB)": 3.54,
      "step": 45,
      "token_acc": 0.99375,
      "train_speed(iter/s)": 0.952573
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.48924446105957,
      "learning_rate": 0.0,
      "loss": 0.02590964138507843,
      "memory(GiB)": 3.54,
      "step": 50,
      "token_acc": 0.99375,
      "train_speed(iter/s)": 0.959945
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.004542836919426918,
      "eval_runtime": 3.0772,
      "eval_samples_per_second": 64.994,
      "eval_steps_per_second": 32.497,
      "eval_token_acc": 0.9975,
      "step": 50
    }
  ],
  "logging_steps": 5,
  "max_steps": 50,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 482188756746240.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
